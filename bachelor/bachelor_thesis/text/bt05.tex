\chapter{Summary \& Outlook}
\label{chap:summaryoutlook}

Todays digital cameras apply a large amount of post-processing on a captured image. Typically, this post-processing aims at creating more visually pleasing, crisp and clean images. Many of these steps are nonlinear, like for instance white balancing to compensate for different light temperature or gamma correction. All these nonlinearities can be summarized as a single function, the camera response function (CRF). However, many algorithms in computer vision require images, where the intensities are approximately linear to the real-world scene radiance. Prominent examples for such algorithms are \emph{Color Constancy} or \emph{Shape from Shading}. Digital cameras are available, of which the direct output of the CCD sensor can be extracted, which is supposed to be linear. Nevertheless, to be able to conduct these algorithms on arbitrary images from all kinds of sources, methods were developed to estimate the CRF of a particular camera. Knowing the CRF facilitates mapping image intensity back to approximately linear image irradiance by inverting the CRF. Recently, several approaches on this topic have been proposed. Most of them require several images taken in constrained environments and thus they can not be applied on arbitrary images.

In this thesis, two approaches on the estimation of the CRF from a single RGB color image are examined. The approach by Ng et \hbox{al.}, ``Using Geometry Invariants for Camera Response Function Estimation'', is physics-based. Locally planar irradiance points (LPIPs) are used to extract information solely related to the particular CRF. If a point has an irradiance geometry that is locally planar, then the second order partial derivatives in the irradiance domain would all be zero. Consequently, an equation called \emph{derivative equality constraint} holds, which is referred to as first order geometry invariant ($G_1$). This quantity does not carry any geometry information and thus is used to estimate the CRF. Therefore, it is shown that $G_1$ has a simple relationship with the gamma curve parameter $\gamma$. A related expression is introduced ($Q(R)$). The subsequent steps are first, extracting LPIPs from an image and computing $G_1$. Then the extracted points get weighted utilizing $Q(R)$ in combination with Bayesian inference to overcome problems with erroneously detected points. The third step is done by an iterative minimization algorithm. It looks for the optimal parameters for a specific CRF model. The utilized model is called generalized gamma curve model (GGCM). Ng et \hbox{al.} introduced this extension to the pure gamma curve model, because it has quite good fit to real-world CRFs in comparison to more conventional models.

Despite thorough studies, including spending much effort on locating potential error sources, we could not achieve satisfying results. The problem first appears when computing $Q(R)$. Due to the fact that $Q(R)$ is strongly related to the applied CRF, histograms are generated, which can be interpreted to estimate the CRF. However, the expected CRF-dependent distribution of the $Q(R)$-values could not be observed. It turned out, that we were not able to successfully perform Bayesian inference on our version of the $Q$-$R$-histograms. Nevertheless, an approach for further examination of this method is proposed.

The second method, proposed by S. Lin et \hbox{al.}, ``Radiometric Calibration from a Single Image'', utilizes the nonlinear edge color distributions emerging by applying a nonlinear CRF. It is shown that the colors on an edge between two distinct regions, which are both colored uniformly, result in a linear combination of the two region colors in scene irradiance. Hence, the edge colors lie on the line spanned by the two region colors in RGB space. After the nonlinear CRF transformation, the edge colors are located on a curve rather than a line. This fact is used to estimate the CRF. For reasons of interpolating over regions of only sparse color coverage, and to overcome very unstable estimates occurring due to the presence of noise, prior knowledge on CRFs is involved. A PCA representation of CRFs is utilized to model the space of characteristic real-world CRFs. Therefore, the CRF space is modeled by a Gaussian mixture model (GMM) of real-world CRFs. The algorithm is subdivided into two main steps. At first, image-specific information is collected by looking for patches of a certain size, containing exactly one edge and two distinct color regions. An observation set is formed. Secondly, the CRF is estimated by incorporating both, the prior model and the image-specific information. The Levenberg-Marquardt minimization routine is used for optimization.

We evaluated the two main steps of this method. At first, both steps are discussed separately, independently from each other, assuming perfect conditions. The goal was to examine how well the method can perform in theory and to determine a set of good parameters for the final evaluation, a stability test.

During the evaluation of the data acquisition step, it turned out, that two parameters mainly determine the quality and size of the resulting observation set. Besides the size of the set, also its coverage of the color space used by the examined image is important. We introduced an algorithm to measure a quantity called color coverage factor $\beta$. Incorporating $\beta$, a brute force approach facilitated finding a good combination of these two most significant parameters.

The second evaluation approach aims at the maximum possible performance of the CRF estimation step. For this purpose, the data acquisition step is skipped and perfect, synthetic data without noise is generated instead. Note that due to the data being synthetically generated, the ground-truth CRF is known. The most influential parameter here is $\lambda$. It balances the impact of image-specific information versus prior knowledge. The most important insight is, that the error of the estimated CRF to the ground-truth CRF can be significantly decreased, when additional knowledge on the type of the CRF is available. This means, that if the CRF is a typical one, then the impact of the prior knowledge should be greater than for very uncommon CRFs, like linear ones. The reason is, that even very noisy and corrupt data in the observation set can not significantly lower the quality of the estimates, if prior knowledge is highly weighted. Vice versa, having a linear CRF, most influence should be passed to the image-specific information. Otherwise, the estimates will remain relatively similar to typical CRFs.

In the final evaluation, we combined both previously examined steps and examined real-world images. Sets of same-camera natural images were compiled to measure the robustness of this method utilizing a leave-one-out (LOO) approach. The main quality criterion determining the actual robustness is the mean error over all three color channels and the standard deviation of the error measurements. It turned out, that the stability of the method is heavily dependent on the chosen parameters, in particular $\lambda$. As expected, if the prior knowledge is weighted more strongly, the method is much more robust. But this does not necessarily imply, that the estimated CRFs are more similar to the ground-truth curves. Only the dissimilarity between a set of CRFs computed from images taken by the same camera is smaller. We compared eight different cameras from prestigious manufacturers. Also an image database, rather intended for color constancy research, is involved. For this set of images, some differences to those from the other cameras were observed. A possible explanation is, that this database is extracted from a video camera, while all the other cameras are usual digital cameras.

All in all, modern digital cameras change the actually measured scene radiance in a vast number of ways. New camera generations have new features, that make the images look more impressive. Therefore, CRF estimation will be challenging the computer vision community for a long time.